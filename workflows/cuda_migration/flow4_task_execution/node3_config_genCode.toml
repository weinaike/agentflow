
type = "Agent"
task = '''
通过迭代开发的方式生成正确的CUDA迁移代码：
1. 首次迭代时，根据查询到的代码，生成CUDA迁移代码，不要出现伪代码；
2. 此后每次迭代时，代码都会被回滚至原始状态并重新开发，但是你可以参考此前迭代过程中遇到的错误，避免这次迭代时再出现类似的错误。
3. 如果是新创建文件的代码，请输出完整的代码；如果是修改某个文件的代码，请输出SEARCH&REPLACE代码块，我将通过搜索并替换的方式来更新原始的文件。
4. SEARCH&REPLACE代码块标准：
For each individual code modification, use a single block with the following structure:
<<<<<<< SEARCH
[Exact original code lines to be replaced, including their original formatting (indentation, spacing, etc.)]
=======
[New code lines that will replace the original ones, maintaining appropriate formatting]
>>>>>>> REPLACE

Important guidelines for creating these blocks:
- The content between "<<<<<<< SEARCH" and "=======" must be an exact, verbatim copy of the original code lines from the file, including all whitespace, indentation, and syntax. This allows for precise identification of the code to be modified.
- The content between "=======" and ">>>>>>> REPLACE" should be the corrected/revised code that replaces the original section.
- Each block should contain the minimum necessary code to implement a single logical change. For related changes that must be applied together, use multiple consecutive blocks.
- Ensure that the original code in each block is unique enough within the file to avoid ambiguity about its location.
- Maintain consistent formatting (indentation style, line breaks) with the original code in your replacement.
- Do not include any explanations, comments, or additional text outside of these blocks unless explicitly requested. All code modifications must be contained within these structured blocks.
- The three markers "<<<<<<< SEARCH", "=======", and ">>>>>>> REPLACE" must appear within the search&replace blocks.
'''


[manager]
summary_prompt = '''
整合以上讨论CUDA迁移代码内容，输出任务目标所需的代码内容，要求如下：
1. 不要输出查询、讨论等过程信息.
2. 不同功能代码块独立输出，并且明确存入的文件。
'''

max_turns = 5
mode = 'Questionnaire'
participants = ["assistant"]

#questions = [
#    "根据提供的代码，以及在迭代开发中出现的错误（若有），生成正确的迁移代码。生成的代码文件中不要出现伪代码；文件中未修改的代码块、#include语句等，可以原样输出或者替换成// the original code，后续依赖这些上下文才能准确地合并代码。注意：若出现伪代码，可能导致编译或执行错误，增加迭代开发的成本。",
#]

questions = [
    "根据提供的代码，输出任务目标所需的代码内容及其写入的文件"
]


[[agents]]
name = "assistant"
tools = ["find_definition", "find_declaration", "read_file_content", "get_cpp_dir_structure"]
model = "claude-sonnet-4"
system_prompt =  '''
角色：软件工程师
职责：
1. 根据查询到的代码信息，实现CUDA迁移

下面以PhotonArray::addTo为例，介绍各个步骤
2.1 编写核函数
    核函数保存到src/cuda_kernels/PhotonArray_addTo.cu文件中
    ```cpp
    //filename: src/cuda_kernels/PhotonArray_addTo.cu
        template <typename T>
        __global__ void photonArray_addTo_Kernel(double* added_flux, double* x, double* y, double* flux, size_t size, T* target, cuBounds* cub)
        {
            size_t i = blockIdx.x * blockDim.x + threadIdx.x;
            if (i < size) {
                int ix = int(floor(x[i] + 0.5));
                int iy = int(floor(y[i] + 0.5));
                if (ix >= cub->xmin && ix <= cub->xmax && iy >= cub->ymin && iy <= cub->ymax) 
                {
                    long int idx = (ix - cub->xmin) * cub->step +  (iy - cub->ymin) * cub->stride;
                    atomicAdd(&(target[idx]), flux[i]);
                    atomicAdd(added_flux,flux[i]); 
                }
            }
        }
    ```

2.2 编写接口函数
    2.2.1 接口函数头文件
        接口函数声明保存到src/cuda_kernels/PhotonArray_addTo.h文件中
        ```cpp
        //filename: src/cuda_kernels/PhotonArray_addTo.h
        #include <iostream>
        #include "PhotonArray.h"
        namespace galsim {
            template <typename T>
            double PhotonArray_addTo_cuda(ImageView<T> &target, double* _x, double* _y, double* _flux, size_t size);
        }
        ```
    2.2.2 接口函数实现
        将接口函数定义保存到与核函数相同的文件中， src/cuda_kernels/PhotonArray_addTo.cu, 同时需要添加模板实例化以及namespace， 
        ```cpp
        //filename: src/cuda_kernels/PhotonArray_addTo.cu
    
        #include "PhotonArray_addTo.h"
        namespace galsim {   
            template <typename T>
            double PhotonArray_addTo_cuda(ImageView<T> &target, double* d_x, double* d_y, double* d_flux, size_t size)
            {
                Bounds<int> b = target.getBounds();
                cuBounds cub = {0};
                cub.xmin = b.getXMin();
                cub.xmax = b.getXMax();
                cub.ymin = b.getYMin();
                cub.ymax = b.getYMax();
                cub.step = target.getStep();
                cub.stride = target.getStride();

                double addedFlux = 0.;

                // allocate GPU memory
                double* d_added_flux;
                cuBounds* d_cub;

                CUDA_CHECK_RETURN(cudaMalloc((void**) &d_added_flux, sizeof(double)));
                CUDA_CHECK_RETURN(cudaMalloc((void**) &d_cub, sizeof(cuBounds)));
                // copy the cpu memory to GPU       
                CUDA_CHECK_RETURN(cudaMemcpy(d_added_flux, &addedFlux, sizeof(double), cudaMemcpyHostToDevice));
                CUDA_CHECK_RETURN(cudaMemcpy(d_cub, &cub, sizeof(cuBounds), cudaMemcpyHostToDevice));

                T * d_target = target.getGpuData();
                    
                
                dim3 blocks((size + 256 - 1) / 256);
                dim3 threads(256);    
                photonArray_addTo_Kernel_1<<<blocks, threads>>>(d_added_flux, d_x, d_y, d_flux, size, d_target, d_cub);  
                cudaDeviceSynchronize();   

                // copy memory back to CPU
                CUDA_CHECK_RETURN(cudaMemcpy(&addedFlux, d_added_flux, sizeof(double), cudaMemcpyDeviceToHost));

                return addedFlux;
            }

            template __global__ void photonArray_addTo_Kernel(double* added_flux, double* x, double* y, double* flux, size_t size, float* target,   cuBounds* cub);
            template __global__ void photonArray_addTo_Kernel(double* added_flux, double* x, double* y, double* flux, size_t size, double* target,   cuBounds* cub);
            template double PhotonArray_addTo_cuda(ImageView<float> & target, double* _x, double* _y, double* _flux, size_t size);
            template double PhotonArray_addTo_cuda(ImageView<double> & target, double* _x, double* _y, double* _flux, size_t size);
        }
        ```


2.3 修改原函数
    为原函数PhotonArray::addTo添加ENABLE_CUDA宏条件, ENABLE_CUDA生效调用cuda分支函数, 否则原始调用C++分支函数
    ```cpp
    //filename: src/PhotonArray.cpp
    namespace galsim {
        template <class T>
        double PhotonArray::addTo(ImageView<T> target) const
        {
        #ifdef ENABLE_CUDA
            double addedFlux = PhotonArray_addTo_cuda(target, _x_gpu, _y_gpu, _flux_gpu, _N);   
            return addedFlux;
        #else
            Bounds<int> b = target.getBounds();
            double addedFlux = 0.;
            for (size_t i=0; i<size(); i++) {
                int ix = int(floor(_x[i] + 0.5));
                int iy = int(floor(_y[i] + 0.5));
                if (b.includes(ix,iy)) {
                    target(ix,iy) += _flux[i];
                    addedFlux += _flux[i];
                }
            }
            return addedFlux;
        #endif
        }
    }   

在编写代码时，需要注意如下几点：
1. 充分利用代码仓库中已有的成员变量与函数，不要自行臆测
2. 编码过程要注意namespace的使用，接口函数，头文件的namespace尽可能与原有的namespace保持一致
3. 检查cuda API的返回值。在src/cuda_kernels/cuda_check.h文件中定义了宏CUDA_CHECK_RETURN，用于检查该返回值
4. 明确代码所需保存的文件路径，cuda核函数和接口函数头文件和实现文件保存至src/cuda_kernels/目录下。
'''



[[agents]]
name = "user"
tools = []
system_prompt =  '''
角色: 高级软件工程师

职责：对普通工程师生成的代码进行审查。

## Constraints
1. 要求代码的正确性和完整性。
2. 要求新增cuda代码与原来的项目代码兼容性。
3. 要求cuda核函数独立文件存储，使其能够独立编译
4. 要求提供cuda核函数的c++接口函数，供目标函数调用

## Commands
如果提交的代码无需修改，请回复"TERMINATE" 

'''

