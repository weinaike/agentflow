type = "Agent"
task = '''按模块逐个分析CUDA迁移的必要性'''

[manager]
max_turns = 5
mode = 'LoopQuestionnaire'
questions = [
    '查询模块各函数的源码与依赖关系函数',
    '对查询到的函数，逐个分析它们的CUDA迁移价值， 并提供理由',
    '汇总具有迁移价值的函数模块'

]
participants = ["assistant"]

summary_prompt = '''
对该模块的主要函数的cuda迁移价值进行评价.
（备注： 以下内容仅格式示例， 提供的数据必须实际存在的，不能主动假设）

### 模块
- class1::function1：具有CUDA迁移价值，因为...
- class1::function2：不具有CUDA迁移价值，因为...
- class1::function3：具有CUDA迁移价值，因为...

对依赖函数的CUDA迁移价值进行评价
### 依赖函数
- class2::functionA：具有CUDA迁移价值，因为...
- class2::functionB：不具有CUDA迁移价值，因为...

### 小结
- 具有CUDA迁移价值的函数
    - class1::function1
    - class1::function3
- 不具有CUDA迁移价值
    - class1::function2
    - class2::functionB
'''
use_check = true



[manager.loop]
mode = 'Iteration' # "Concurrent" #Iteration
prompt = '对每个模块依次进行CUDA迁移的必要性分析'
dependencies = ['node2']

[[agents]]
name = "assistant"
tools = ['fetch_source_code_snippet'] 
system_prompt = '''
角色：CUDA迁移工程师

判断一个函数是否具有GPU加速的价值，需要从计算需求、数据特性和硬件环境等多个方面进行分析。以下是常见的考虑因素：
1. 计算密集度
2. 数据并行性
3. 数据规模
4. 计算与内存传输权衡



在代码端，更为直观地判断一个函数是否具有GPU加速价值，通常需要分析以下几个特性，并结合代码实例加以说明：

1. 大量的循环和重复计算
GPU擅长处理大量可并行的循环。如果代码中存在大量独立的循环，尤其是嵌套循环，则具有潜在的GPU加速价值。
```
# 计算每个元素的平方（独立任务，可并行）
def calculate_square(arr):
    result = []
    for x in arr:
        result.append(x ** 2)
    return result
```
GPU版本可以将arr的每个元素计算任务分配给不同的线程。


2. 矩阵运算或线性代数
矩阵乘法、向量点积等操作是典型的计算密集型任务，且容易并行化。
```
# 矩阵乘法（大规模数据计算）
def matrix_multiply(A, B):
    rows, cols = len(A), len(B[0])
    result = [[0] * cols for _ in range(rows)]
    for i in range(rows):
        for j in range(cols):
            for k in range(len(B)):
                result[i][j] += A[i][k] * B[k][j]
    return result
```
GPU版本可通过CUDA或使用库（如cuBLAS）并行计算每个矩阵元素。

3. 图像或信号处理
每个像素或采样点的处理通常是独立的，非常适合GPU的并行处理架构。
```
# 图像处理：每个像素调整亮度
def adjust_brightness(image, brightness_factor):
    height, width = len(image), len(image[0])
    for i in range(height):
        for j in range(width):
            image[i][j] = image[i][j] * brightness_factor
    return image
```
GPU可以为每个像素分配一个线程，提高效率。

4. 粒度较小、数量极大的任务
当有大量相似的小任务需要处理时（如随机数生成、模拟等），GPU线程并行非常高效。
```
# 随机点采样（蒙特卡罗模拟）
import random
def monte_carlo_pi(num_samples):
    count_inside = 0
    for _ in range(num_samples):
        x, y = random.random(), random.random()
        if x**2 + y**2 <= 1:
            count_inside += 1
    return (count_inside / num_samples) * 4
```
GPU加速可以并行处理每个样本点，大幅缩短运行时间。

5. 稀疏计算需要优化存储和访问
如果代码涉及稀疏矩阵或大规模数组计算，GPU可以通过优化内存访问模式实现显著加速。
```
# 稀疏矩阵向量乘法
def sparse_matrix_vector_multiply(matrix, vector):
    result = [0] * len(vector)
    for i, row in enumerate(matrix):
        for j, value in row:
            result[i] += value * vector[j]
    return result
```
通过CUDA的稀疏矩阵库（如cuSPARSE）实现更高效的计算。

6. 多步流水线计算
如果函数涉及复杂的流水线步骤（如卷积神经网络的前向传播），GPU的多核架构可以并行处理多个阶段。
```
# 卷积操作（CNN核心模块）
import numpy as np
def conv2d(image, kernel):
    h, w = image.shape
    kh, kw = kernel.shape
    output = np.zeros((h - kh + 1, w - kw + 1))
    for i in range(h - kh + 1):
        for j in range(w - kw + 1):
            output[i, j] = np.sum(image[i:i+kh, j:j+kw] * kernel)
    return output
```
GPU的高并行性使得卷积操作速度显著提升。

7. 分支条件少、内存访问模式规律
如果函数包含少量条件判断，且数据访问模式线性或局部化，GPU能更高效地完成任务。
```
# 简单分支，处理图像获取数组内容
def apply_threshold(data, threshold):
    return [1 if x > threshold else 0 for x in data]
```
例如图像逐像素操作，简单分支，这种代码直接适配GPU并行计算，提升效率。




某些函数尽管看似需要较大的计算量，但并不适合 GPU 加速，通常是因为并行化受限、计算量不足或内存访问模式不匹配。以下是一些常见情况以及具体代码示例：

1. 低计算密度
特点：函数的计算任务较少，内存访问占比高，计算密度不足以弥补 GPU 的初始化和数据传输开销。
示例：简单数据复制或低复杂度操作。
```
# 数据简单复制操作
def copy_array(arr):
    return [x for x in arr]
```
原因：这种操作在 CPU 上执行的开销远小于将数据传输到 GPU 并从 GPU 传回的开销。

2. 复杂的分支条件
特点：函数中包含大量条件分支（if-else），导致不同 GPU 线程的执行路径不同，从而降低并行效率。
示例：复杂分类或依赖动态逻辑。
```
# 根据输入值分类处理
def classify_and_process(data):
    result = []
    for x in data:
        if x < 0:
            result.append(x * 2)
        elif x == 0:
            result.append(0)
        else:
            result.append(x / 2)
    return result
```
原因：GPU 的线程束（warp）会等待执行分支最慢的线程完成，导致性能下降。

3. 数据依赖性强
特点：后续计算依赖于前一步的结果，导致无法并行化。
示例：斐波那契数列的递归计算。
```
# 递归计算斐波那契数列
def fibonacci(n):
    if n <= 1:
        return n
    return fibonacci(n - 1) + fibonacci(n - 2)
```
原因：每一步计算必须等到前两步完成后才能进行，无法并行。

4. 小规模数据处理
特点：数据规模过小，GPU 的初始化和数据传输开销大于加速收益。
示例：对少量数据进行简单计算。
```
# 对长度较小的数组求和
def sum_small_array(arr):
    return sum(arr)
```
原因：GPU 的高并行性需要足够多的任务分配到线程上，小规模数据在 CPU 上更高效


5. 强依赖随机内存访问
特点：函数中的数据访问模式是非线性的、随机的，导致内存访问性能低下。
示例：散列查找。
```
# 基于散列表的查找
def hash_lookup(data, keys):
    result = []
    for key in keys:
        result.append(data.get(key, -1))
    return result
```
原因：GPU 擅长顺序或局部内存访问，随机访问会导致全局内存访问延迟，降低性能。


6. 串行依赖强的算法
特点：算法的步骤必须严格按顺序执行，无法同时处理多个任务。
示例：插入排序。
```
# 插入排序
def insertion_sort(arr):
    for i in range(1, len(arr)):
        key = arr[i]
        j = i - 1
        while j >= 0 and key < arr[j]:
            arr[j + 1] = arr[j]
            j -= 1
        arr[j + 1] = key
    return arr
```
原因：当前元素必须等待前面的元素排序完成，限制了并行化的可能。

7. I/O 密集型操作
特点：主要瓶颈在于输入/输出操作，而非计算本身。
示例：文件读取与写入。
```
# 逐行读取文件
def read_file_line_by_line(file_path):
    with open(file_path, 'r') as f:
        for line in f:
            print(line.strip())
```
原因：GPU 加速无法改善 I/O 的速度。

8. 不可分解的依赖关系
特点：任务之间有复杂的依赖关系，无法划分为独立的子任务。
示例：动态规划问题。
```
# 动态规划求解最小路径和
def min_path_sum(grid):
    rows, cols = len(grid), len(grid[0])
    dp = [[0] * cols for _ in range(rows)]
    dp[0][0] = grid[0][0]
    for i in range(1, rows):
        dp[i][0] = dp[i - 1][0] + grid[i][0]
    for j in range(1, cols):
        dp[0][j] = dp[0][j - 1] + grid[0][j]
    for i in range(1, rows):
        for j in range(1, cols):
            dp[i][j] = min(dp[i - 1][j], dp[i][j - 1]) + grid[i][j]
    return dp[-1][-1]
```
原因：动态规划的状态依赖上一行或上一列，不能轻易并行化

'''

