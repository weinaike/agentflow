{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方案1：ListMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**文档预处理：**\n",
    "1. PDF文档处理 \n",
    "2. 文本分割\n",
    "3. 摘要生成\n",
    "4. 存入listMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import AssistantAgent, UserProxyAgent, ListMemory\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# 1. 文档处理\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "with open(\"project_docs.txt\") as f:\n",
    "    docs = [Document(page_content=text) for text in text_splitter.split_text(f.read())]\n",
    "\n",
    "# 2. 生成摘要\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "summary_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "summaries = summary_chain.run(docs)\n",
    "\n",
    "# 3. 创建Agent并配置内存\n",
    "knowledge_memory = ListMemory()\n",
    "knowledge_memory.add(summaries)  # 添加生成的摘要\n",
    "\n",
    "assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    system_message=\"你是一个项目助手，当用户询问项目相关问题时，请参考以下知识库：\\n{{知识库}}\",\n",
    "    memory=knowledge_memory,\n",
    "    llm_config={\"config_list\": config_list}\n",
    ")\n",
    "\n",
    "user_proxy = UserProxyAgent(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stuff chain，一次性生成摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.memory import ListMemory, MemoryContent, MemoryMimeType\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "import re\n",
    "import nest_asyncio\n",
    "\n",
    "# 允许嵌套的事件循环\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()\n",
    "\n",
    "# 自定义章节分块器\n",
    "class ChapterAwareSplitter:\n",
    "    def __init__(self, chunk_size=2000):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chapter_pattern = re.compile(\n",
    "            r'(^#+\\s.+)|(^第[一二三四五六七八九十]+章\\s.+)|(^\\d+\\.\\d+\\s.+)', \n",
    "            re.MULTILINE\n",
    "        )\n",
    "\n",
    "    def split_text(self, text):\n",
    "        chapters = []\n",
    "        buffer = \"\"\n",
    "        \n",
    "        # 使用finditer来获取所有的章节开头，这样可以更好地控制不打断章节\n",
    "        for match in self.chapter_pattern.finditer(text):\n",
    "            start_pos = match.start()\n",
    "            \n",
    "            if len(buffer) + start_pos > self.chunk_size and buffer:\n",
    "                chapters.append(buffer)\n",
    "                buffer = \"\"\n",
    "                \n",
    "            buffer += text[:start_pos]\n",
    "            text = text[start_pos:]\n",
    "            \n",
    "            chapter_text = match.group()\n",
    "            if len(buffer) + len(chapter_text) > self.chunk_size and buffer:\n",
    "                chapters.append(buffer)\n",
    "                buffer = \"\"\n",
    "            buffer += chapter_text\n",
    "        \n",
    "        if text:  # 添加剩余的文本\n",
    "            buffer += text\n",
    "            \n",
    "        if buffer:\n",
    "            chapters.append(buffer)\n",
    "            \n",
    "        return chapters\n",
    "\n",
    "# PDF处理器类\n",
    "class PDFKnowledgeProcessor:\n",
    "    def __init__(self, pdf_path, prompt_template):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.prompt = PromptTemplate.from_template(prompt_template)\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=0,\n",
    "            model=\"gpt-4o-2024-08-06\",\n",
    "            base_url=\"https://api2.road2all.com/v1\",\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "\n",
    "    def process_pdf(self):\n",
    "        from langchain_core.documents import Document\n",
    "        # 1. 正确加载PDF内容\n",
    "        try:\n",
    "            loader = PyPDFLoader(self.pdf_path)\n",
    "            pages = loader.load()\n",
    "            full_text = \"\\n\".join([page.page_content for page in pages])  # 直接提取文本\n",
    "        except Exception as e:\n",
    "            print(f\"PDF加载失败: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "        # 2. 章节分块\n",
    "        splitter = ChapterAwareSplitter()\n",
    "        chunks = splitter.split_text(full_text)\n",
    "        print(f\"成功分割为 {len(chunks)} 个章节块\")\n",
    "\n",
    "        # 将字符串块转换为Document对象\n",
    "        documents = [\n",
    "            Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\"source\": self.pdf_path}  # 添加元数据\n",
    "            ) for chunk in chunks\n",
    "        ]\n",
    "        \n",
    "        # 3. 生成摘要\n",
    "        try:\n",
    "            chain = load_summarize_chain(\n",
    "                self.llm,\n",
    "                chain_type=\"map_reduce\",\n",
    "                map_prompt=self.prompt,\n",
    "                combine_prompt=self.prompt,\n",
    "                verbose=True\n",
    "            )\n",
    "            result = chain.invoke({\"input_documents\": documents})\n",
    "            return result[\"output_text\"]\n",
    "        except Exception as e:\n",
    "            print(f\"摘要生成失败: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "# 使用示例\n",
    "async def main():\n",
    "    # 配置参数\n",
    "    PDF_PATH = \"/home/www/AgentFlow/agentflow/docs/GalsimToolkit.pdf\"\n",
    "    PROMPT_TEMPLATE = \"\"\"请用简洁的语言总结以下内容：\n",
    "    \n",
    "    {text}\n",
    "    \n",
    "    关键要点：\"\"\"\n",
    "\n",
    "    # 处理PDF\n",
    "    processor = PDFKnowledgeProcessor(PDF_PATH, PROMPT_TEMPLATE)\n",
    "    knowledge = processor.process_pdf()\n",
    "    \n",
    "    if knowledge:\n",
    "        print(\"\\n生成的知识库内容：\\n\", knowledge)\n",
    "    else:\n",
    "        print(\"知识库生成失败，请检查日志\")\n",
    "        return\n",
    "\n",
    "    # 配置助手Agent\n",
    "    memory = ListMemory()\n",
    "    await memory.add(MemoryContent(\n",
    "        content=knowledge,\n",
    "        mime_type=MemoryMimeType.TEXT))\n",
    "\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model = \"gpt-4o-2024-08-06\",\n",
    "        base_url = \"https://api2.road2all.com/v1\",\n",
    "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    assistant_agent = AssistantAgent(\n",
    "        name=\"project_assistant\",\n",
    "        system_message=\"你是一个项目助手，回答时请参考以下知识：\\n{{知识库}}\",\n",
    "        model_client=model_client,\n",
    "        memory=[memory]\n",
    "    )\n",
    "\n",
    "    stream = assistant_agent.run_stream(task=\"请根据文档说明项目使用的主要技术方法。\")\n",
    "    await Console(stream)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### refine chain，章节prompt+全文prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_core.memory import ListMemory, MemoryContent, MemoryMimeType\n",
    "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "import re\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()\n",
    "\n",
    "class ChapterAwareSplitter:\n",
    "    def __init__(self, chunk_size=2000):\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chapter_pattern = re.compile(\n",
    "            r'(^#+\\s.+)|(^第[一二三四五六七八九十]+章\\s.+)|(^\\d+\\.\\d+\\s.+)', \n",
    "            re.MULTILINE\n",
    "        )\n",
    "\n",
    "    def split_text(self, text):\n",
    "        chapters = []\n",
    "        buffer = \"\"\n",
    "        \n",
    "        for match in self.chapter_pattern.finditer(text):\n",
    "            start_pos = match.start()\n",
    "            \n",
    "            if len(buffer) + start_pos > self.chunk_size and buffer:\n",
    "                chapters.append(buffer)\n",
    "                buffer = \"\"\n",
    "                \n",
    "            buffer += text[:start_pos]\n",
    "            text = text[start_pos:]\n",
    "            \n",
    "            chapter_text = match.group()\n",
    "            if len(buffer) + len(chapter_text) > self.chunk_size and buffer:\n",
    "                chapters.append(buffer)\n",
    "                buffer = \"\"\n",
    "            buffer += chapter_text\n",
    "        \n",
    "        if text:  \n",
    "            buffer += text\n",
    "            \n",
    "        if buffer:\n",
    "            chapters.append(buffer)\n",
    "            \n",
    "        return chapters\n",
    "\n",
    "class PDFKnowledgeProcessor:\n",
    "    def __init__(self, pdf_path, map_prompt, combine_prompt):\n",
    "        self.pdf_path = pdf_path\n",
    "        self.map_prompt = map_prompt\n",
    "        self.combine_prompt = combine_prompt\n",
    "        self.llm = ChatOpenAI(\n",
    "            temperature=0,\n",
    "            model=\"gpt-4o-2024-08-06\",\n",
    "            base_url=\"https://api2.road2all.com/v1\",\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "\n",
    "    def process_pdf(self):\n",
    "        from langchain_core.documents import Document\n",
    "        try:\n",
    "            loader = PyPDFLoader(self.pdf_path)\n",
    "            pages = loader.load()\n",
    "            full_text = \"\\n\".join([page.page_content for page in pages])\n",
    "        except Exception as e:\n",
    "            print(f\"PDF加载失败: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "        splitter = ChapterAwareSplitter()\n",
    "        chunks = splitter.split_text(full_text)\n",
    "        print(f\"成功分割为 {len(chunks)} 个章节块\")\n",
    "\n",
    "        # 空文档过滤\n",
    "        valid_chunks = []\n",
    "        for chunk in chunks:\n",
    "            if len(chunk.strip()) < 50:  # 过滤空内容\n",
    "                continue\n",
    "            if \"未定义\" in chunk or \"待补充\" in chunk:  # 过滤占位内容\n",
    "                continue\n",
    "            valid_chunks.append(chunk)\n",
    "        \n",
    "        if not valid_chunks:\n",
    "            print(\"无有效内容需要处理\")\n",
    "            return \"\"\n",
    "\n",
    "        documents = [\n",
    "            Document(\n",
    "                page_content=chunk,\n",
    "                metadata={\n",
    "                    \"source\": self.pdf_path,\n",
    "                    \"length\": len(chunk)\n",
    "                    }\n",
    "            ) for chunk in valid_chunks\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            chain = load_summarize_chain(\n",
    "                self.llm,\n",
    "                chain_type=\"refine\",\n",
    "                question_prompt=PromptTemplate.from_template(self.map_prompt),\n",
    "                refine_prompt=PromptTemplate.from_template(self.combine_prompt),\n",
    "                return_intermediate_steps=True,\n",
    "                input_key=\"input_documents\",\n",
    "                output_key=\"output_text\"\n",
    "            )\n",
    "\n",
    "            filtered_documents = []\n",
    "            for doc in documents:\n",
    "                if \"无意义内容，无需总结\" in doc.page_content:\n",
    "                    continue\n",
    "                filtered_documents.append(doc)\n",
    "                # 调用链前，确保输入文档有效\n",
    "            if not filtered_documents:\n",
    "                print(\"没有有效文档需要处理\")\n",
    "                return \"\"\n",
    "\n",
    "            # 调用链并捕获异常\n",
    "            try:\n",
    "                result = chain.invoke({\"input_documents\": filtered_documents})\n",
    "                return result[\"output_text\"]\n",
    "            except Exception as e:\n",
    "                print(f\"链调用失败: {str(e)}\")\n",
    "                return \"\"\n",
    "        except Exception as e:\n",
    "            print(f\"摘要生成失败: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "async def main():\n",
    "    PDF_PATH = \"/home/www/AgentFlow/agentflow/docs/GalsimToolkit.pdf\"\n",
    "    map_prompt = \"\"\"\n",
    "    请仔细阅读以下文本内容，并回答以下问题（用中文，保持简洁）：\n",
    "    如果内容中没有涉及以下任何一项，请直接回复“无意义内容，无需总结”：\n",
    "    1. 技术方法/算法描述\n",
    "    2. 代码模块/组件的结构说明\n",
    "    3. 功能实现的关键步骤或流程\n",
    "    4. 项目整体架构或作用说明\n",
    "\n",
    "    如果内容有实际技术信息，请参考以下内容总结：\n",
    "    1. \"技术方法\": \"...\",\n",
    "    2. \"模块结构\": \"...\",\n",
    "    3. \"关键步骤\": \"...\",\n",
    "    4. \"作用说明\": \"...\"\n",
    "    文本内容：\n",
    "    {text}\n",
    "    \"\"\"\n",
    "\n",
    "    combine_prompt = \"\"\"\n",
    "    请根据以下分块摘要，生成项目的技术概述文档。要求：\n",
    "    1. **技术方法**：总结项目的核心技术、算法或框架。\n",
    "    2. **架构设计**：描述代码的整体架构和模块间关系。\n",
    "    3. **功能模块**：列举主要功能模块及其作用。\n",
    "    4. **实现细节**：说明关键步骤或技术难点的解决方案。\n",
    "    5. **应用场景**：项目适用的使用场景或目标用户。\n",
    "    6. **优势特点**：项目的独特优势或创新点。\n",
    "\n",
    "    请用结构化的方式呈现，分点说明，避免冗余。\n",
    "\n",
    "    \n",
    "    分块摘要：\n",
    "    {text}\n",
    "    \"\"\"\n",
    "\n",
    "    processor = PDFKnowledgeProcessor(\n",
    "        pdf_path=PDF_PATH,\n",
    "        map_prompt=map_prompt,\n",
    "        combine_prompt=combine_prompt\n",
    "    )\n",
    "    knowledge = processor.process_pdf()\n",
    "    \n",
    "    if knowledge:\n",
    "        print(\"\\n生成的知识库内容：\\n\", knowledge)\n",
    "    else:\n",
    "        print(\"知识库生成失败，请检查日志\")\n",
    "        return\n",
    "\n",
    "    memory = ListMemory()\n",
    "    await memory.add(MemoryContent(\n",
    "        content=knowledge,\n",
    "        mime_type=MemoryMimeType.TEXT))\n",
    "\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        base_url=\"https://api2.road2all.com/v1\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    assistant_agent = AssistantAgent(\n",
    "        name=\"project_assistant\",\n",
    "        system_message=\"你是一个项目助手，回答时请参考以下知识：\\n{{知识库}}\",\n",
    "        model_client=model_client,\n",
    "        memory=[memory]\n",
    "    )\n",
    "\n",
    "    stream = assistant_agent.run_stream(task=\"请根据文档总结项目的基本信息。\")\n",
    "    await Console(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功分割为 22 个章节块\n",
      "\n",
      "生成的知识库内容：\n",
      " # 项目技术概述文档\n",
      "\n",
      "## 1. 技术方法\n",
      "- **核心技术**：项目使用了GAL SIM软件包来模拟天文图像中的噪声和图像处理。主要技术包括噪声相关函数的估计、噪声美白技术以及重卷积算法。\n",
      "- **算法**：噪声美白技术通过添加额外的噪声来使图像中的噪声场变得近似不相关和稳定。重卷积算法用于处理低分辨率下的图像变换。\n",
      "- **框架**：项目基于GAL SIM框架，提供了多种图像渲染方法，包括离散傅里叶变换（DFT）和光子射击。\n",
      "\n",
      "## 2. 架构设计\n",
      "- **整体架构**：项目代码分为多个模块，包括噪声处理模块、图像渲染模块、变换模块等。\n",
      "- **模块间关系**：噪声处理模块负责估计和处理图像中的噪声，图像渲染模块负责生成模拟图像，变换模块处理图像的几何变换。\n",
      "\n",
      "## 3. 功能模块\n",
      "- **噪声处理模块**：估计和处理图像中的噪声，包括噪声相关函数的计算和噪声美白。\n",
      "- **图像渲染模块**：使用DFT和光子射击方法生成模拟图像。\n",
      "- **变换模块**：处理图像的几何变换，包括剪切和放大。\n",
      "- **重卷积模块**：处理低分辨率图像的重卷积。\n",
      "\n",
      "## 4. 实现细节\n",
      "- **关键步骤**：噪声美白通过计算噪声的功率谱并添加额外的噪声来实现。重卷积算法通过模拟低分辨率下的图像变换来实现。\n",
      "- **技术难点解决方案**：使用高精度的傅里叶变换和光子射击方法来确保图像渲染的准确性。通过参数调节来优化噪声处理和图像渲染的性能。\n",
      "\n",
      "## 5. 应用场景\n",
      "- **使用场景**：项目适用于天文图像的模拟和处理，特别是在弱透镜剪切和放大测量中。\n",
      "- **目标用户**：天文学家、天文数据分析师以及需要高精度图像模拟的研究人员。\n",
      "\n",
      "## 6. 优势特点\n",
      "- **独特优势**：项目提供了多种图像渲染方法，能够处理复杂的噪声和图像变换。噪声美白技术能够显著降低噪声相关性。\n",
      "- **创新点**：通过重卷积算法处理低分辨率图像变换，确保在不同分辨率下的图像处理精度。提供了灵活的参数调节机制以优化性能。\n",
      "---------- user ----------\n",
      "请根据文档总结项目的基本信息。\n",
      "---------- project_assistant ----------\n",
      "[MemoryContent(content='# 项目技术概述文档\\n\\n## 1. 技术方法\\n- **核心技术**：项目使用了GAL SIM软件包来模拟天文图像中的噪声和图像处理。主要技术包括噪声相关函数的估计、噪声美白技术以及重卷积算法。\\n- **算法**：噪声美白技术通过添加额外的噪声来使图像中的噪声场变得近似不相关和稳定。重卷积算法用于处理低分辨率下的图像变换。\\n- **框架**：项目基于GAL SIM框架，提供了多种图像渲染方法，包括离散傅里叶变换（DFT）和光子射击。\\n\\n## 2. 架构设计\\n- **整体架构**：项目代码分为多个模块，包括噪声处理模块、图像渲染模块、变换模块等。\\n- **模块间关系**：噪声处理模块负责估计和处理图像中的噪声，图像渲染模块负责生成模拟图像，变换模块处理图像的几何变换。\\n\\n## 3. 功能模块\\n- **噪声处理模块**：估计和处理图像中的噪声，包括噪声相关函数的计算和噪声美白。\\n- **图像渲染模块**：使用DFT和光子射击方法生成模拟图像。\\n- **变换模块**：处理图像的几何变换，包括剪切和放大。\\n- **重卷积模块**：处理低分辨率图像的重卷积。\\n\\n## 4. 实现细节\\n- **关键步骤**：噪声美白通过计算噪声的功率谱并添加额外的噪声来实现。重卷积算法通过模拟低分辨率下的图像变换来实现。\\n- **技术难点解决方案**：使用高精度的傅里叶变换和光子射击方法来确保图像渲染的准确性。通过参数调节来优化噪声处理和图像渲染的性能。\\n\\n## 5. 应用场景\\n- **使用场景**：项目适用于天文图像的模拟和处理，特别是在弱透镜剪切和放大测量中。\\n- **目标用户**：天文学家、天文数据分析师以及需要高精度图像模拟的研究人员。\\n\\n## 6. 优势特点\\n- **独特优势**：项目提供了多种图像渲染方法，能够处理复杂的噪声和图像变换。噪声美白技术能够显著降低噪声相关性。\\n- **创新点**：通过重卷积算法处理低分辨率图像变换，确保在不同分辨率下的图像处理精度。提供了灵活的参数调节机制以优化性能。', mime_type=<MemoryMimeType.TEXT: 'text/plain'>, metadata=None)]\n",
      "---------- project_assistant ----------\n",
      "**项目基本信息总结：**\n",
      "\n",
      "1. **技术方法**：项目依托于GAL SIM软件包，用于模拟天文图像中的噪声和图像处理。采用噪声相关函数估计、噪声美白技术及重卷积算法。其中，噪声美白通过添加噪声使图像噪声场更稳定，重卷积算法用于低分辨率的图像变换。\n",
      "\n",
      "2. **架构设计**：项目代码划分为多个模块，包括噪声处理模块、图像渲染模块与变换模块。噪声处理负责估计与处理图像噪声，图像渲染生成模拟图像，变换模块则进行图像几何变换。\n",
      "\n",
      "3. **功能模块**：\n",
      "   - **噪声处理模块**：计算噪声相关函数与进行噪声美白。\n",
      "   - **图像渲染模块**：利用DFT和光子射击生成模拟图像。\n",
      "   - **变换模块**：执行图像的几何变换，如剪切与放大。\n",
      "   - **重卷积模块**：处理低分辨率图像的重卷积。\n",
      "\n",
      "4. **实现细节**：关键步骤包括计算噪声功率谱并添加噪声进行美白，使用高精度傅里叶变换与光子射击方法提高图像渲染准确性，参数调节优化性能。\n",
      "\n",
      "5. **应用场景**：主要用于天文图像的模拟和处理，特别是应用于弱透镜剪切和放大测量。\n",
      "\n",
      "6. **目标用户**：天文学家、天文数据分析师及需要高精度图像模拟的研究人员。\n",
      "\n",
      "7. **优势特点**：\n",
      "   - 提供多样图像渲染方法，能处理复杂的噪声与图像变换。\n",
      "   - 噪声美白技术降低噪声相关性。\n",
      "   - 重卷积算法确保不同分辨率下图像处理精度，灵活参数调节优化性能。\n"
     ]
    }
   ],
   "source": [
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### langchain rag tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回答结果：\n",
      " Galsim是一个用于模拟天文学图像的开源软件库。它的全名是\"Galaxies and Stars Image Simulation\"。Galsim的主要功能包括：\n",
      "\n",
      "1. **模拟天体图像**：用于模拟星系和恒星的图像，可以帮助天文学家在观测数据分析中进行校准和测试。\n",
      "\n",
      "2. **多种模型支持**：支持各种星系和恒星的光学模型，比如Sérsic轮廓、光学器件的点扩散函数(PSF)模拟等。\n",
      "\n",
      "3. **卷积和变形操作**：可以对图像进行卷积、变形（如剪切和放大）等操作，以精确模拟天体望远镜的观测效应。\n",
      "\n",
      "4. **处理大规模仿真**：能够处理大规模的天体图像仿真，适用于应对大面积天空观测时的数据需求。\n",
      "\n",
      "5. **灵活的用户接口**：提供了一个强大的Python接口，方便用户定制各种模拟场景。\n",
      "\n",
      "Galsim在天文研究中非常有用，特别是在弱引力透镜、宇宙微波背景辐射等领域的模拟和分析中。\n"
     ]
    }
   ],
   "source": [
    "# 安装必要库\n",
    "# pip install pyautogen langchain pypdf chromadb\n",
    "\n",
    "import os\n",
    "import getpass\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from autogen import AssistantAgent\n",
    "\n",
    "\n",
    "# 1. 配置第三方API参数\n",
    "load_dotenv()\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "BASE_URL = \"https://api2.road2all.com/v1\" \n",
    "\n",
    "\n",
    "# 2. 加载并处理PDF文档\n",
    "def load_and_process_pdf(pdf_path):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200\n",
    "    )\n",
    "    splits = text_splitter.split_documents(pages)\n",
    "    return splits\n",
    "\n",
    "# 3. 创建向量数据库\n",
    "def create_vector_store(documents):\n",
    "    # 配置自定义端点\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        openai_api_base=BASE_URL, \n",
    "        model=\"text-embedding-3-large\", \n",
    "    )\n",
    "    \n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=\"./langchain_vectors\"\n",
    "    )\n",
    "    return vectorstore\n",
    "\n",
    "# 4. 创建检索工具\n",
    "def create_retrieval_tool(vectorstore):\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    llm = ChatOpenAI(\n",
    "        openai_api_base=BASE_URL,\n",
    "        temperature=0,\n",
    "        model=\"gpt-4o-2024-08-06\"\n",
    "    )\n",
    "    system_prompt = (\n",
    "        \"Use the given context to answer the question. \"\n",
    "        \"If you don't know the answer, say you don't know. \"\n",
    "        \"Use three sentence maximum and keep the answer concise. \"\n",
    "        \"Context: {context}\"\n",
    "    )\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    qa_chain = create_stuff_documents_chain(llm, prompt)\n",
    "    chain = create_retrieval_chain(retriever, qa_chain)\n",
    "\n",
    "    def retrieval_tool(query):\n",
    "        return chain.run({\"input\": query})\n",
    "\n",
    "    return retrieval_tool\n",
    "\n",
    "\n",
    "# 5. 创建增强版AssistantAgent\n",
    "class PDFAssistant(AssistantAgent):\n",
    "    def __init__(self, retrieval_tool):\n",
    "        config_list = [{\n",
    "            \"model\": \"gpt-4o-2024-08-06\",\n",
    "            \"base_url\": BASE_URL,\n",
    "            \"api_type\": \"openai\"\n",
    "        }]\n",
    "        \n",
    "        super().__init__(\n",
    "            name=\"pdf_assistant\",\n",
    "            llm_config={\n",
    "                \"config_list\": config_list,\n",
    "                \"tools\": [{\n",
    "                    \"type\": \"function\",\n",
    "                    \"function\": {\n",
    "                        \"name\": \"retrieve_tool\",\n",
    "                        \"description\": \"从PDF文档检索信息\",\n",
    "                        \"parameters\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"query\": {\"type\": \"string\"}\n",
    "                            },\n",
    "                            \"required\": [\"query\"]\n",
    "                        }\n",
    "                    }\n",
    "                }]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        self.register_function(function_map={\"retrieve_tool\": retrieval_tool})\n",
    "\n",
    "    def query(self, question):\n",
    "        response = self.generate_reply(\n",
    "            messages=[{\"content\": question, \"role\": \"user\"}]\n",
    "        )\n",
    "        return response\n",
    "\n",
    "\n",
    "# 主程序流程\n",
    "if __name__ == \"__main__\":\n",
    "    documents = load_and_process_pdf(\"/home/www/AgentFlow/agentflow/docs/GalsimToolkit.pdf\")\n",
    "    vectorstore = create_vector_store(documents)\n",
    "    retrieval_tool = create_retrieval_tool(vectorstore)\n",
    "    assistant = PDFAssistant(retrieval_tool)\n",
    "    answer = assistant.query(\"请简要介绍Galsim\")\n",
    "    print(\"回答结果：\\n\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
